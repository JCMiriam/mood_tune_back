import pandas as pd
import torch
import numpy as np
import faiss  # ğŸ”¥ Importar FAISS para bÃºsquedas rÃ¡pidas
from sentence_transformers import SentenceTransformer
import os

# ğŸ“Œ Ruta relativa correcta del archivo de embeddings generados con RoBERTa
EMBEDDINGS_FILE = os.path.join(os.path.dirname(__file__), "embeddings_roberta2.pkl")

# ğŸ“Œ Verificar si el archivo existe antes de cargarlo
if not os.path.exists(EMBEDDINGS_FILE):
    raise FileNotFoundError(f"âŒ Error: No se encontrÃ³ el archivo {EMBEDDINGS_FILE}")

# ğŸ“Œ Cargar el dataset con los embeddings
try:
    df = pd.read_pickle(EMBEDDINGS_FILE)
    print("âœ… Archivo de embeddings cargado correctamente.")
except Exception as e:
    raise RuntimeError(f"âŒ Error al cargar el archivo Pickle: {e}")

# ğŸ“Œ Convertir embeddings a NumPy arrays de tipo float32 (para FAISS)
df['embedding'] = df['embedding'].apply(lambda x: np.array(x, dtype=np.float32))

# ğŸ“Œ Crear un Ã­ndice FAISS para bÃºsqueda rÃ¡pida (usamos IndexFlatIP para mÃ¡xima precisiÃ³n)
embeddings = np.stack(df["embedding"].values)  # Convertir embeddings a matriz
index = faiss.IndexFlatIP(embeddings.shape[1])  # Ãndice con similitud coseno
index.add(embeddings)  # Cargar los embeddings en FAISS

# ğŸ“Œ Cargar modelo RoBERTa en GPU si estÃ¡ disponible
device = "cuda" if torch.cuda.is_available() else "cpu"
model = SentenceTransformer('all-roberta-large-v1', device=device)

# ğŸ“Œ Almacenar objetos en un diccionario para fÃ¡cil acceso desde otros archivos
model_data = {
    "df": df,
    "index": index,
    "model": model
}
