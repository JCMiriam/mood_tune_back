import os
import sys
import importlib.util
import subprocess
import pandas as pd
import torch
import numpy as np


# ðŸ“Œ Ruta del archivo de embeddings
EMBEDDINGS_FILE = r"C:\Users\solan\mood_tune_back\src\models\embeddings_roberta2.pkl" # RUTA DONDE ESTÃ‰N METIDOS LOS EMBEDDINGS 

# ðŸ“Œ Cargar el dataset con los embeddings
print("ðŸ”„ Cargando datos de embeddings...")
df = pd.read_pickle(EMBEDDINGS_FILE)

# ðŸ“Œ Convertir embeddings a NumPy array si estÃ¡n en listas
if isinstance(df['embedding'][0], list):
    df['embedding'] = df['embedding'].apply(lambda x: np.array(x))

embeddings_matrix = np.vstack(df['embedding'].values).astype('float32')

# ðŸ“Œ Crear Ã­ndice FAISS
dimension = embeddings_matrix.shape[1]
index = faiss.IndexFlatL2(dimension)  
index.add(embeddings_matrix)

print("âœ… FAISS index creado.")

# ðŸ“Œ Cargar modelo RoBERTa en GPU si estÃ¡ disponible
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âš¡ Usando: {device.upper()}")

model = SentenceTransformer('all-roberta-large-v1', device=device)

# ðŸ“Œ Guardar los objetos en un diccionario
model_data = {
    "df": df,
    "index": index,
    "model": model
}

print("âœ… Modelo y datos listos para usar.")
